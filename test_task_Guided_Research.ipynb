{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Reward Section--\n",
      "last loss 0.2625430226325989\n",
      "current loss 0.2614516019821167\n",
      "0.06536290049552917\n",
      "--Punishment Section--\n",
      "last loss 0.06536290049552917\n",
      "current loss 1.2611252069473267\n",
      "--Reward Section--\n",
      "last loss 1.2611252069473267\n",
      "current loss 0.26002320647239685\n",
      "0.06500580161809921\n",
      "--Punishment Section--\n",
      "last loss 0.06500580161809921\n",
      "current loss 1.2596988677978516\n",
      "--Reward Section--\n",
      "last loss 1.2596988677978516\n",
      "current loss 0.2586153447628021\n",
      "0.06465383619070053\n",
      "--Punishment Section--\n",
      "last loss 0.06465383619070053\n",
      "current loss 1.2582951784133911\n",
      "--Reward Section--\n",
      "last loss 1.2582951784133911\n",
      "current loss 0.25721797347068787\n",
      "0.06430449336767197\n",
      "--Punishment Section--\n",
      "last loss 0.06430449336767197\n",
      "current loss 1.256899356842041\n",
      "--Reward Section--\n",
      "last loss 1.256899356842041\n",
      "current loss 0.2558262348175049\n",
      "0.06395655870437622\n",
      "--Punishment Section--\n",
      "last loss 0.06395655870437622\n",
      "current loss 1.2555160522460938\n",
      "--Reward Section--\n",
      "last loss 1.2555160522460938\n",
      "current loss 0.2545281946659088\n",
      "0.0636320486664772\n",
      "--Punishment Section--\n",
      "last loss 0.0636320486664772\n",
      "current loss 1.2542370557785034\n",
      "--Reward Section--\n",
      "last loss 1.2542370557785034\n",
      "current loss 0.253259539604187\n",
      "0.06331488490104675\n",
      "--Punishment Section--\n",
      "last loss 0.06331488490104675\n",
      "current loss 1.2529691457748413\n",
      "--Reward Section--\n",
      "last loss 1.2529691457748413\n",
      "current loss 0.25205057859420776\n",
      "0.06301264464855194\n",
      "--Punishment Section--\n",
      "last loss 0.06301264464855194\n",
      "current loss 1.2517809867858887\n",
      "--Reward Section--\n",
      "last loss 1.2517809867858887\n",
      "current loss 0.2508692741394043\n",
      "0.06271731853485107\n",
      "--Punishment Section--\n",
      "last loss 0.06271731853485107\n",
      "current loss 1.25059974193573\n",
      "--Reward Section--\n",
      "last loss 1.25059974193573\n",
      "current loss 0.24969366192817688\n",
      "0.06242341548204422\n",
      "--Punishment Section--\n",
      "last loss 0.06242341548204422\n",
      "current loss 1.249428629875183\n",
      "--Reward Section--\n",
      "last loss 1.249428629875183\n",
      "current loss 0.24853137135505676\n",
      "0.06213284283876419\n",
      "--Punishment Section--\n",
      "last loss 0.06213284283876419\n",
      "current loss 1.2482624053955078\n",
      "--Reward Section--\n",
      "last loss 1.2482624053955078\n",
      "current loss 0.2473735809326172\n",
      "0.0618433952331543\n",
      "--Punishment Section--\n",
      "last loss 0.0618433952331543\n",
      "current loss 1.247100830078125\n",
      "--Reward Section--\n",
      "last loss 1.247100830078125\n",
      "current loss 0.24622021615505219\n",
      "0.061555054038763046\n",
      "--Punishment Section--\n",
      "last loss 0.061555054038763046\n",
      "current loss 1.2459449768066406\n",
      "--Reward Section--\n",
      "last loss 1.2459449768066406\n",
      "current loss 0.24507054686546326\n",
      "0.061267636716365814\n",
      "--Punishment Section--\n",
      "last loss 0.061267636716365814\n",
      "current loss 1.244807243347168\n",
      "--Reward Section--\n",
      "last loss 1.244807243347168\n",
      "current loss 0.2439166158437729\n",
      "0.06097915396094322\n",
      "--Punishment Section--\n",
      "last loss 0.06097915396094322\n",
      "current loss 1.2436532974243164\n",
      "--Reward Section--\n",
      "last loss 1.2436532974243164\n",
      "current loss 0.24276582896709442\n",
      "0.060691457241773605\n",
      "--Punishment Section--\n",
      "last loss 0.060691457241773605\n",
      "current loss 1.2425034046173096\n",
      "--Reward Section--\n",
      "last loss 1.2425034046173096\n",
      "current loss 0.2416319102048874\n",
      "0.06040797755122185\n",
      "--Punishment Section--\n",
      "last loss 0.06040797755122185\n",
      "current loss 1.2413628101348877\n",
      "--Reward Section--\n",
      "last loss 1.2413628101348877\n",
      "current loss 0.24053047597408295\n",
      "0.06013261899352074\n",
      "--Punishment Section--\n",
      "last loss 0.06013261899352074\n",
      "current loss 1.240267038345337\n",
      "--Reward Section--\n",
      "last loss 1.240267038345337\n",
      "current loss 0.23943766951560974\n",
      "0.059859417378902435\n",
      "--Punishment Section--\n",
      "last loss 0.059859417378902435\n",
      "current loss 1.2391880750656128\n",
      "--Reward Section--\n",
      "last loss 1.2391880750656128\n",
      "current loss 0.2383435219526291\n",
      "0.05958588048815727\n",
      "--Punishment Section--\n",
      "last loss 0.05958588048815727\n",
      "current loss 1.2380938529968262\n",
      "--Reward Section--\n",
      "last loss 1.2380938529968262\n",
      "current loss 0.23726747930049896\n",
      "0.05931686982512474\n",
      "--Punishment Section--\n",
      "last loss 0.05931686982512474\n",
      "current loss 1.2370206117630005\n",
      "--Reward Section--\n",
      "last loss 1.2370206117630005\n",
      "current loss 0.23620876669883728\n",
      "0.05905219167470932\n",
      "--Punishment Section--\n",
      "last loss 0.05905219167470932\n",
      "current loss 1.2359569072723389\n",
      "--Reward Section--\n",
      "last loss 1.2359569072723389\n",
      "current loss 0.23515236377716064\n",
      "0.05878809094429016\n",
      "--Punishment Section--\n",
      "last loss 0.05878809094429016\n",
      "current loss 1.2348994016647339\n",
      "--Reward Section--\n",
      "last loss 1.2348994016647339\n",
      "current loss 0.23410025238990784\n",
      "0.05852506309747696\n",
      "--Punishment Section--\n",
      "last loss 0.05852506309747696\n",
      "current loss 1.23385751247406\n",
      "--Reward Section--\n",
      "last loss 1.23385751247406\n",
      "current loss 0.2330407053232193\n",
      "0.058260176330804825\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# defining architecture of the network\n",
    "input_data, hidden_layers, output_size, batch_size = 100, 5, 1, 10\n",
    "\n",
    "\n",
    "# Create dummy input and target tensors (data)\n",
    "x = torch.randn(batch_size, input_data)\n",
    "y = torch.tensor([[1.0], [0.0], [0.0], [1.0], [1.0], [1.0], [0.0], [0.0], [1.0], [1.0]])\n",
    "\n",
    "\n",
    "# model creation\n",
    "model = nn.Sequential(nn.Linear(input_data, hidden_layers),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(hidden_layers, output_size),\n",
    "                     nn.Sigmoid())\n",
    "\n",
    "\n",
    "\n",
    "# loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# optimizer for the network\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum = 0.05)\n",
    "\n",
    "var_loss = []\n",
    "# Gradient Descent\n",
    "for epoch in range(50):\n",
    "    # Predicted value \n",
    "    y_pred = model(x)\n",
    "    #print (y_pred)\n",
    "    # Loss calculation\n",
    "    loss = criterion(y_pred, y)\n",
    "    #print('epoch: ', epoch,' loss: ', loss.item())\n",
    "    \n",
    "    #var_loss.append(loss.item())\n",
    "    #Reward; Punishment functions\n",
    "    if (epoch == 0):\n",
    "        var_loss.append(loss.item())\n",
    "        #fin_loss = loss\n",
    "        \n",
    "    elif (var_loss[epoch-1] > loss.item()):\n",
    "        print ('--Reward Section--')\n",
    "        print ('last loss',var_loss[epoch-1])\n",
    "        print ('current loss', loss.item())\n",
    "        # reward logic\n",
    "        loss = (loss*0.25)\n",
    "        print (loss.item())\n",
    "        var_loss.append(loss.item())\n",
    "        #print (fin_loss.item())\n",
    "    else:\n",
    "        print ('--Punishment Section--') \n",
    "        #punishment logic\n",
    "        loss = loss + 1\n",
    "        print ('last loss',var_loss[epoch-1])\n",
    "        print ('current loss', loss.item())\n",
    "        var_loss.append(loss.item())\n",
    "        #print(loss.item())\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    #backpropogation on the loss\n",
    "    loss.backward()\n",
    "    \n",
    "    # parameters update\n",
    "    optimizer.step()\n",
    "#print (var_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
